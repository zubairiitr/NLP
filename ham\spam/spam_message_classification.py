# -*- coding: utf-8 -*-
"""Spam_Message_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XNcUfGj5CdVaqmpkuGnSxGAcT2R8Zl-T

# Spam Message Classification

# 1) Data Preprocessing
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# data file spam.tsv

df = pd.read_csv('spam.tsv', sep='\t')

df.head()  # display first five record

"""The data sheet with four columns: "message," "label," "length," and a fourth column that records the number of punctuation marks in each individual message in the "message" column. Each message in the "message" column is associated with a label in the "label" column, which specifies whether the message is classified as "ham" or "spam." The "length" column records the total number of characters in each message. Finally, the fourth column records the number of punctuation marks in each message."""

df.isna().sum() #  cheak for missing values in data set

df.tail()    # display last five rows of data

df.describe()

df['label'].value_counts()/ (len(df))  # percentage of how many record is ham or spam in data set

"""The dataset is imbalanced, with 86% of the data classified as ham and only 13% classified as spam. Due to this imbalance, it may not be advisable to train on the complete dataset as it could introduce bias."""

df['label'].value_counts()

"""If you want to reduce the number of ham data points, you can randomly select a subset of the ham data and remove them from the dataset until you have a comparable number of ham and spam data points. However, it's important to note that reducing the number of spam data points can negatively impact the performance of any machine learning models you train on the new dataset, as you are essentially throwing away potentially useful information.

Alternatively, you could try oversampling the ham data by duplicating existing ham data points or generating new ones using techniques like data augmentation. This would allow you to create a balanced dataset while retaining all of the original data points.

Ultimately, the best approach depends on the specific goals of your analysis and the characteristics of your data.
"""

ham = df[df['label'] == 'ham']
spam = df[df['label'] == 'spam']

ham.shape, spam.shape

ham = ham.sample(spam.shape[0])

ham.shape, spam.shape

data = ham.append(spam, ignore_index=True)

data.shape

data['label'].value_counts()

data.head()

plt.hist(data[data['label'] == 'ham']['length'], bins = 100, alpha = 0.7)
plt.hist(data[data['label'] == 'spam']['length'], bins = 100, alpha = 0.7)
plt.show()

"""The initial interpretation involves visualizing the data to distinguish between spam and ham messages based on message length. A basic rule-of-thumb is messages longer than 100 characters are labeled as spam, and messages shorter than 100 characters are labeled as ham. However, this is a simplistic interpretation and may not be accurate in all cases."""

plt.hist(data[data['label'] == 'ham']['punct'], bins = 100, alpha = 0.7)
plt.hist(data[data['label'] == 'spam']['punct'], bins = 100, alpha = 0.7)
plt.show()

"""The punctuation marks are plotted on the x-axis in the given figure, but it is difficult to make a decision based solely on visualization in this case."""

data

"""Great, now that our data is ready, we can proceed with splitting it into training and test datasets. This is an important step in machine learning where we divide our data into two sets: the training dataset is used to train our machine learning model, and the test dataset is used to evaluate its performance. By splitting our data into these two sets, we can ensure that our model is not simply memorizing the training data, but can generalize to new, unseen data."""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test =  train_test_split(data['message'], data['label'], test_size = 0.3, random_state =0, shuffle = True)

1494 * 0.3

X_train.shape

X_test.shape



"""# 2) Building the Model (Random Forest)"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier

from sklearn.pipeline import Pipeline

classifier = Pipeline([("tfidf", TfidfVectorizer()) , ("classifier", RandomForestClassifier(n_estimators=100))])

classifier.fit(X_train, y_train)

"""# 3) Predicting the results (Random Forest)"""

y_pred = classifier.predict(X_test)

y_test, y_pred

"""Once we have trained our machine learning model on the training dataset, we can evaluate its performance on the test dataset using various metrics such as accuracy_score, confusion_matrix, and classification_report.

The accuracy_score is a measure of the percentage of correctly predicted labels. It is calculated by dividing the number of correctly predicted labels by the total number of labels.

The confusion_matrix is a table that shows the number of true positives, true negatives, false positives, and false negatives for each class. It is a useful tool for evaluating the performance of a classification model.

The classification_report provides a summary of various metrics such as precision, recall, and F1-score for each class. These metrics provide a more detailed understanding of the performance of our model.

Overall, these metrics can help you determine the effectiveness of our machine learning model and identify areas for improvement.
"""

from sklearn.metrics import classification_report, accuracy_score, confusion_matrix

accuracy_score(y_test, y_pred)

0.9465478841870824 * 449

confusion_matrix(y_test, y_pred)

print(classification_report(y_test, y_pred))



"""# 4) Building the Model (SVM)"""

from sklearn.svm import SVC

svm = Pipeline([("tfidf", TfidfVectorizer()) , ("classifier", SVC(C = 100, gamma='auto'))])

svm.fit(X_train, y_train)

"""# 5) Predicting the results (SVM)"""

y_pred = svm.predict(X_test)

accuracy_score(y_test, y_pred)

confusion_matrix(y_test, y_pred)

print(classification_report(y_test, y_pred))

""" To test our trained random forest model on a hand-crafted input dataset, we can follow these steps:

Prepare our input data in the same format as your original dataset, with the same features and data types.

Load your trained random forest model into memory.

Use the predict() method of the model to generate a prediction for our input data. The output of this method will be the predicted label (ham or spam) for each input data point.
"""

test1 = ['Hello, You are learning natural Language Processing']
test2 = ['Hope you are doing good and learning new things !']
test3 = ['Congratulations, You won a lottery ticket worth $1 Million ! To claim call on 446677']

print(classifier.predict(test1))
print(classifier.predict(test2))
print(classifier.predict(test3))

"""To test our trained SVM model on a hand-crafted input dataset, we can follow these steps:

Prepare our input data in the same format as your original dataset, with the same features and data types.

Load our trained SVM model into memory.

Use the predict() method of the model to generate a prediction for your input data. The output of this method will be the predicted label (ham or spam) for each input data point.
"""

print(svm.predict(test1))
print(svm.predict(test2))
print(svm.predict(test3))